{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import device_setting, seed_torch\n",
    "from data_manager import AnomalyDataManager\n",
    "from model import ResNet50MetricModel, MLP\n",
    "from metric_layer import ArcMarginProduct#, MetricModel\n",
    "from resnet import ResNet18\n",
    "# from trainer import Trainer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosine_similarity(np_array_a, np_array_b):\n",
    "    eps = 1e-9\n",
    "    dis = np_array_a @ np_array_b.T\n",
    "    norm_a = (np_array_a * np_array_a).sum(1, keepdims=True) ** (0.5)\n",
    "    norm_b = (np_array_b * np_array_b).sum(1, keepdims=True) ** (0.5)\n",
    "    similarity_matrix = dis / (norm_a+eps) / (norm_b.T+eps)\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_array_cosine_similarity(np_array_a, np_array_b):\n",
    "    eps = 1e-9\n",
    "    dis = np_array_a @ np_array_b.T\n",
    "    print(dis)\n",
    "    norm_a = (np_array_a * np_array_a).sum() ** (0.5)\n",
    "    norm_b = (np_array_b * np_array_b).sum() ** (0.5)\n",
    "    similarity_matrix = dis / (norm_a+eps) / (norm_b.T+eps)\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricModel(nn.Module):\n",
    "    def __init__(self, model, metric_layer, num_classes):\n",
    "        super(MetricModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.metric_layer = metric_layer\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        feature = self.model(input)\n",
    "        output = self.metric_layer(feature, label)\n",
    "\n",
    "        return feature, output\n",
    "\n",
    "    def set_center_of_classes(self, train_dataloader, feature_dim, device):\n",
    "        self.cog_list = [np.array([0]*feature_dim) for _ in range(self.num_classes)]\n",
    "\n",
    "        num_data_list = [0]*self.num_classes\n",
    "        for input, label in train_dataloader:\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "            feature, output = self.forward(input, label)\n",
    "            _, pred_label = torch.max(output, 1)\n",
    "            feature_cpu = feature.cpu().detach().numpy()\n",
    "            for i, lbl in enumerate(pred_label.cpu().detach().numpy()):\n",
    "                self.cog_list[lbl] = self.cog_list[lbl] + feature_cpu[i]\n",
    "\n",
    "            for lb in label.cpu().detach().numpy():\n",
    "                num_data_list[lb] = num_data_list[lb] + 1\n",
    "        \n",
    "        print(num_data_list)\n",
    "        self.cog_sum = copy.deepcopy(self.cog_list)\n",
    "        # print(self.cog_list[-1])\n",
    "        for i in range(self.num_classes):\n",
    "            self.cog_list[i] = self.cog_list[i] / num_data_list[i]\n",
    "\n",
    "        pass\n",
    "\n",
    "    def inference(self, input):\n",
    "    #    r\"\"\"\n",
    "    #     attribute: calc cosine similarity and return prob_classe\n",
    "    #         prob_classes: torch.tensor (bs, class)  \n",
    "    #                       (x, y) mean mdoel predicts the probability of data x belonging y class\n",
    "    #    \"\"\"\n",
    "\n",
    "        feature = self.model(input)\n",
    "        prob_classes = calc_cosine_similarity(feature.cpu().detach().numpy(), np.array(self.cog_list))\n",
    "\n",
    "        return torch.from_numpy(prob_classes).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "dataset = 'kdd'\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "max_epoch = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "feature_dim = 25\n",
    "gpu = 0\n",
    "device = device_setting(gpu=gpu)\n",
    "data_manager = AnomalyDataManager(dataset=dataset, data_dir=data_dir, trans=None, anomaly_label=9, data_num=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = data_manager.get_num_classes()\n",
    "dataloader_dict = data_manager.build_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch(0)\n",
    "model = MLP(in_features=data_manager.input_dim, out_features=feature_dim)\n",
    "metric_layer = ArcMarginProduct(in_features=feature_dim, out_features=num_classes, s=30.0, m=0.50, easy_margin=False)\n",
    "optimizer = optim.Adam(list(model.parameters()) + list(metric_layer.parameters()), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "load_epoch = 20\n",
    "model_path = '../models/kdd/model_epoch_{}.pth'.format(load_epoch)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = model.to(device)\n",
    "metric_layer = metric_layer.to(device)\n",
    "metric_model = MetricModel(model, metric_layer, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_model.set_center_of_classes(dataloader_dict['train'], feature_dim, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = [67343, 41214, 890, 3599, 2931, 892, 1493, 3633, 2646, 201, 956, 53, 8, 7, 10, 30, 11, 20, 4, 18, 9, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "metric_model.cog_sum[i] / data_num[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(metric_model.cog_list).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state = 0, perplexity = 30, n_iter = 1000)\n",
    "\n",
    "X_embedded = tsne.fit_transform(metric_model.cog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (30, 30))\n",
    "# # lbl = dataset_dict['train'][:][1][i]\n",
    "# plt.scatter(X_embedded[:, 0], \n",
    "#             X_embedded[:, 1],\n",
    "#             c=range(len(X_embedded)), \n",
    "#             cmap=plt.cm.jet, \n",
    "#             edgecolor='none', \n",
    "#             # label = lbl,\n",
    "#             # alpha=0.7,\n",
    "#             s=100)\n",
    "\n",
    "# plt.colorbar(aspect=40, pad=0.08, orientation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# eval model\n",
    "acc = 0\n",
    "metric_model.eval()\n",
    "pred_hist = [0]*num_classes\n",
    "\n",
    "for data, label in dataloader_dict['train']: \n",
    "    data = data.to(device)\n",
    "    # label = label.to(device)\n",
    "    probs = metric_model.inference(data)\n",
    "    _, pred_label = torch.max(probs, 1)\n",
    "    for l in pred_label.cpu().detach().numpy():\n",
    "        pred_hist[l] += 1\n",
    "    acc += torch.sum(pred_label == label).item()\n",
    "\n",
    "acc = acc / len(dataloader_dict['train'].dataset)\n",
    "# plot, print result\n",
    "print('Train accuracy: {:4f}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric_model.eval()\n",
    "normal_acc = 0\n",
    "anomaly_detection_acc = 0\n",
    "anomly_label_num = 0\n",
    "for data, label in dataloader_dict['test']:\n",
    "    data = data.to(device)\n",
    "    # 学習にない異常データ（ラベル22~）はその他ラベル-1とする\n",
    "    # label_mask = label > 21\n",
    "    # label[label_mask] = -1\n",
    "    # label = label.to(device)\n",
    "    probs = metric_model.inference(data)\n",
    "    # print(model(data[1]))\n",
    "    # print(metric_model.cog_list[1])\n",
    "    # print(probs[1])\n",
    "    pred_values, pred_label = torch.max(probs, 1)\n",
    "    # print(pred_values)\n",
    "    # print(pred_label)\n",
    "    # print(label)\n",
    "    normal_acc += torch.sum(pred_label == label).item()\n",
    "    # break\n",
    "    anomaly_mask = pred_values < 0.9\n",
    "    # print(pred_label)\n",
    "    anomly_label_num = anomly_label_num + label_mask.sum()\n",
    "    pred_label[anomaly_mask] = -1\n",
    "    anomaly_detection_acc += torch.sum(pred_label == label).item()\n",
    "\n",
    "normal_acc = normal_acc / len(dataloader_dict['test'].dataset)\n",
    "anomaly_detection_acc = anomaly_detection_acc / len(dataloader_dict['test'].dataset)\n",
    "print('Test Normal accuracy: {:4f}'.format(normal_acc))\n",
    "print('Test Anomaly Detection accuracy: {:4f}'.format(anomaly_detection_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異常か正常かのみの判断\n",
    "acc = 0\n",
    "metric_model.eval()\n",
    "pred_hist = [0]*num_classes\n",
    "\n",
    "for data, label in dataloader_dict['train']: \n",
    "    data = data.to(device)\n",
    "    # label = label.to(device)\n",
    "    probs = metric_model.inference(data)\n",
    "    _, pred_label = torch.max(probs, 1)\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i] != 0:\n",
    "            # print(pred_label[i])\n",
    "            pred_label[i] = 1\n",
    "        if label[i] != 0:\n",
    "            label[i] = 1\n",
    "    acc += torch.sum(pred_label == label).item()\n",
    "\n",
    "acc = acc / len(dataloader_dict['train'].dataset)\n",
    "# plot, print result\n",
    "print('Train accuracy: {:4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異常か正常かのみの判断\n",
    "acc = 0\n",
    "metric_model.eval()\n",
    "pred_hist = [0]*num_classes\n",
    "\n",
    "for data, label in dataloader_dict['test']: \n",
    "    data = data.to(device)\n",
    "    # label = label.to(device)\n",
    "    probs = metric_model.inference(data)\n",
    "    _, pred_label = torch.max(probs, 1)\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i] != 0:\n",
    "            # print(pred_label[i])\n",
    "            pred_label[i] = 1\n",
    "        if label[i] != 0:\n",
    "            label[i] = 1\n",
    "    acc += torch.sum(pred_label == label).item()\n",
    "\n",
    "acc = acc / len(dataloader_dict['test'].dataset)\n",
    "# plot, print result\n",
    "print('Train accuracy: {:4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ff6ab8f38a67cb98fe6e77fa99caf109bfee3f4b4c75d0924a20577fd922a97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
